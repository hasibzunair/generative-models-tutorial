{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtWJdzBMYAp3"
      },
      "source": [
        "# Building and applying Generative Models using PyTorch\n",
        "\n",
        "**Author:** [Hasib Zunair](https://hasibzunair.github.io/)<br>\n",
        "**Date created:** 2024/03/20<br>\n",
        "**Last modified:** 2024/06/10<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00frjOfsYAp7"
      },
      "source": [
        "## 2. Finetuning a LLM to follow instructions (Instruction finetuning)\n",
        "\n",
        "Pretrained LLMs are good at text completion, but not good at following instructions.\n",
        "\n",
        "Here we build a model to follow instructions. Instruction finetuned models can usually perform many tasks. An example:\n",
        "\n",
        "Convert 45 kilometers to meters (Instruction) -> 45 kilometers is 45000 meters. (Desired Response)\n",
        "\n",
        "Instruction finetuning is often referred to as \"supervised instruction finetuning\" because it involves training a model on a dataset where the input-output pairs are explicitly provided."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twettqlFYAp8",
        "outputId": "adb396f5-9956-4f6f-ade5-fff184fc80a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LLMs-from-scratch'...\n",
            "remote: Enumerating objects: 3452, done.\u001b[K\n",
            "remote: Counting objects: 100% (994/994), done.\u001b[K\n",
            "remote: Compressing objects: 100% (228/228), done.\u001b[K\n",
            "remote: Total 3452 (delta 835), reused 834 (delta 766), pack-reused 2458\u001b[K\n",
            "Receiving objects: 100% (3452/3452), 9.60 MiB | 8.45 MiB/s, done.\n",
            "Resolving deltas: 100% (2161/2161), done.\n",
            "/content/LLMs-from-scratch/ch07/01_main-chapter-code\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/rasbt/LLMs-from-scratch\n",
        "%cd LLMs-from-scratch/ch07/01_main-chapter-code/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKBV4_TXYAp-",
        "outputId": "624294ea-73f8-43e6-b1c1-c008ffb37ab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.1 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.6.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n",
            "Requirement already satisfied: tensorflow==2.15.0 in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\n",
            "matplotlib version: 3.7.1\n",
            "numpy version: 1.25.2\n",
            "tiktoken version: 0.7.0\n",
            "torch version: 2.3.0+cu121\n",
            "tensorflow version: 2.15.0\n",
            "pandas version: 2.0.3\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "!pip install tiktoken\n",
        "!pip install tensorflow==2.15.0\n",
        "\n",
        "pkgs = [\"matplotlib\",\n",
        "        \"numpy\",\n",
        "        \"tiktoken\",\n",
        "        \"torch\",\n",
        "        \"tensorflow\", # For OpenAI's pretrained weights\n",
        "        \"pandas\"      # Dataset loading\n",
        "       ]\n",
        "for p in pkgs:\n",
        "    print(f\"{p} version: {version(p)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MreyRpRNNBOI"
      },
      "source": [
        "### Prepare dataset\n",
        "\n",
        "Download the instruction dataset. It consists of instruction, input and output text pairs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fcJFED7LKeq",
        "outputId": "0e009bc2-b013-4742-9660-15b8d26c47ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries: 1100\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import urllib\n",
        "\n",
        "\n",
        "def download_and_load_file(file_path, url):\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        with urllib.request.urlopen(url) as response:\n",
        "            text_data = response.read().decode('utf-8')\n",
        "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "            file.write(text_data)\n",
        "    else:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            text_data = file.read()\n",
        "\n",
        "    with open(file_path, \"r\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "file_path = \"instruction-data.json\"\n",
        "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
        "\n",
        "data = download_and_load_file(file_path, url)\n",
        "print(\"Number of entries:\", len(data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9CkROeJNfof"
      },
      "source": [
        "Each item in the `data` list we loaded from the JSON file above is a dictionary in the following form:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-4On2iqLKhV",
        "outputId": "b242814f-a960-49d9-8d23-61d99d1cc755"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example entry:\n",
            "\n",
            " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
          ]
        }
      ],
      "source": [
        "print(\"Example entry:\\n\\n\", data[50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CCRg2RrNYbs",
        "outputId": "4204b7a8-baae-4e0b-c4be-8c64180f802f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Another example entry:\n",
            "\n",
            " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
          ]
        }
      ],
      "source": [
        "print(\"Another example entry:\\n\\n\", data[999])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyNsJ3R0Nq87"
      },
      "source": [
        "We use Alpaca-style prompt formatting, which was the original prompt template for instruction finetuning. For more details, see https://crfm.stanford.edu/2023/03/13/alpaca.html.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rbdV5TsBLKkE"
      },
      "outputs": [],
      "source": [
        "# format the input that we will pass as input to the LLM\n",
        "def format_input(entry):\n",
        "    instruction_text = (\n",
        "        f\"Below is an instruction that describes a task. \"\n",
        "        f\"Write a response that appropriately completes the request.\"\n",
        "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "    )\n",
        "\n",
        "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
        "\n",
        "    return instruction_text + input_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0WpbkUZLKmC",
        "outputId": "610d3bbc-4a63-48aa-8258-477a27b7ccd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Identify the correct spelling of the following word.\n",
            "\n",
            "### Input:\n",
            "Ocassion\n",
            "\n",
            "### Response:\n",
            "The correct spelling is 'Occasion.'\n"
          ]
        }
      ],
      "source": [
        "# A formatted response with input field looks like as shown below\n",
        "model_input = format_input(data[50])\n",
        "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
        "\n",
        "print(model_input + desired_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVOnXNpDLKoH",
        "outputId": "5c451787-655a-4ca0-b310-a4cdd7598ec9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What is an antonym of 'complicated'?\n",
            "\n",
            "### Response:\n",
            "An antonym of 'complicated' is 'simple'.\n"
          ]
        }
      ],
      "source": [
        "# Below is a formatted response without input field\n",
        "model_input = format_input(data[999])\n",
        "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
        "\n",
        "print(model_input + desired_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "c9yTuQKmPA8Y"
      },
      "outputs": [],
      "source": [
        "# Split to train, val and test\n",
        "train_portion = int(len(data) * 0.85)  # 85% for training\n",
        "test_portion = int(len(data) * 0.1)   # 10% for testing\n",
        "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
        "\n",
        "train_data = data[:train_portion]\n",
        "test_data = data[train_portion:train_portion + test_portion]\n",
        "val_data = data[train_portion + test_portion:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fcowq7GaLKqh",
        "outputId": "b522ee42-38de-468a-c9d8-f062bd715139"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set length: 935\n",
            "Validation set length: 55\n",
            "Test set length: 110\n"
          ]
        }
      ],
      "source": [
        "print(\"Training set length:\", len(train_data))\n",
        "print(\"Validation set length:\", len(val_data))\n",
        "print(\"Test set length:\", len(test_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZS1b2HLPLbB"
      },
      "source": [
        "### Create data loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dBBXXPKSLKs9"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "POGQKfS4LKvr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class InstructionDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "\n",
        "        # Pre-tokenize texts\n",
        "        self.encoded_texts = []\n",
        "        for entry in data:\n",
        "            instruction_plus_input = format_input(entry)\n",
        "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
        "            full_text = instruction_plus_input + response_text\n",
        "            self.encoded_texts.append(\n",
        "                tokenizer.encode(full_text)\n",
        "            )\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.encoded_texts[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzugulD-LKyV",
        "outputId": "ec9f3f34-52d6-4027-d292-b16d1089a7fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bvyh1S5BPd4v"
      },
      "outputs": [],
      "source": [
        "def custom_collate_fn(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    ignore_index=-100,\n",
        "    allowed_max_length=None,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs and targets\n",
        "    inputs_lst, targets_lst = [], []\n",
        "    for item in batch:\n",
        "        # Add an <|endoftext|> token\n",
        "        item += [pad_token_id]\n",
        "        # Pad sequences to max_length\n",
        "        padded = item + [pad_token_id] * (batch_max_length - len(item))\n",
        "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
        "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
        "\n",
        "        # Replace all but the first padding tokens in targets by ignore_index\n",
        "        mask = targets == pad_token_id\n",
        "        indices = torch.nonzero(mask).squeeze()\n",
        "        if indices.numel() > 1:\n",
        "            targets[indices[1:]] = ignore_index\n",
        "\n",
        "        # Optionally truncate to maximum sequence length\n",
        "        if allowed_max_length is not None:\n",
        "            inputs = inputs[:allowed_max_length]\n",
        "            targets = targets[:allowed_max_length]\n",
        "\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "\n",
        "    return inputs_tensor, targets_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWchoV4YPd7O",
        "outputId": "e8ba6c43-b75f-485e-f455-6341f432cef4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "from functools import partial\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "customized_collate_fn = partial(custom_collate_fn, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "VX0Hkw4BPd9n"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_dataset = InstructionDataset(train_data, tokenizer)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=True,\n",
        "    drop_last=True\n",
        ")\n",
        "\n",
        "val_dataset = InstructionDataset(val_data, tokenizer)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False\n",
        ")\n",
        "\n",
        "test_dataset = InstructionDataset(test_data, tokenizer)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af6BFqPNP6li",
        "outputId": "f022c434-e655-4812-a289-ba3f8e100c34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 58]) torch.Size([8, 58])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 57]) torch.Size([8, 57])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n"
          ]
        }
      ],
      "source": [
        "print(\"Train loader:\")\n",
        "for x, y in train_loader:\n",
        "    print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYXzUKNWPeCP",
        "outputId": "fa708760-529f-49f8-a6c5-b7537e8c13e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21106, 318, 281, 12064, 326, 8477, 257, 4876, 13, 19430, 257, 2882, 326, 20431, 32543, 262, 2581, 13, 198, 198, 21017, 46486, 25, 198, 30003, 6525, 262, 6827, 1262, 257, 985, 576, 13, 198, 198, 21017, 23412, 25, 198, 464, 5156, 318, 845, 13779, 13, 198, 198, 21017, 18261, 25, 198, 464, 5156, 318, 355, 13779, 355, 257, 4936, 13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, "
          ]
        }
      ],
      "source": [
        "for i in x[0]:\n",
        "    print(i.item(), end=\", \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VRCWUx4PeEy",
        "outputId": "22ac3d1d-5712-45a4-e69b-41199cd3cfc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "318, 281, 12064, 326, 8477, 257, 4876, 13, 19430, 257, 2882, 326, 20431, 32543, 262, 2581, 13, 198, 198, 21017, 46486, 25, 198, 30003, 6525, 262, 6827, 1262, 257, 985, 576, 13, 198, 198, 21017, 23412, 25, 198, 464, 5156, 318, 845, 13779, 13, 198, 198, 21017, 18261, 25, 198, 464, 5156, 318, 355, 13779, 355, 257, 4936, 13, 50256, -100, -100, -100, -100, -100, -100, -100, -100, -100, "
          ]
        }
      ],
      "source": [
        "for i in y[0]:\n",
        "    print(i.item(), end=\", \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NDJS2C-QC26"
      },
      "source": [
        "### Initialize a LLM with pretrained weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnGj-R77PeHM",
        "outputId": "420f271f-8fe2-44c9-a518-53caa6c4cbc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 53.5kiB/s]\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 575kiB/s]\n",
            "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 60.6kiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [01:08<00:00, 7.27MiB/s]\n",
            "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 4.30MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 471k/471k [00:01<00:00, 335kiB/s]\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:01<00:00, 326kiB/s]\n"
          ]
        }
      ],
      "source": [
        "from gpt_download import download_and_load_gpt2\n",
        "from previous_chapters import GPTModel, load_weights_into_gpt\n",
        "\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
        "\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWX8phKfhYxr"
      },
      "source": [
        "To ensure that the model was loaded corrected, let's double-check that it generates coherent text."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "input_text = format_input(val_data[0])\n",
        "print(input_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boqeA0c3Zzgo",
        "outputId": "c4d7afa1-193e-4a2a-c0fb-7b0e2665ea2a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from previous_chapters import (\n",
        "    generate,\n",
        "    text_to_token_ids,\n",
        "    token_ids_to_text\n",
        ")\n",
        "\n",
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(input_text, tokenizer),\n",
        "    max_new_tokens=35,\n",
        "    context_size=BASE_CONFIG[\"context_length\"],\n",
        "    eos_id=50256,\n",
        ")\n",
        "\n",
        "generated_text = token_ids_to_text(token_ids, tokenizer)"
      ],
      "metadata": {
        "id": "dLvSi5-qZz5a"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_text = generated_text[len(input_text):].strip()\n",
        "print(response_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PU1S-7orZ8gK",
        "outputId": "c13adfa9-179c-4647-a483-6b1c19b638c0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Instruction:\n",
            "\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
            "\n",
            "### Instruction:\n",
            "\n",
            "Convert the active\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the model is not good off-the-shelf."
      ],
      "metadata": {
        "id": "8EAVD8p3aHtu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkmJKdY-RRWY"
      },
      "source": [
        "### Finetuning the LLM on instruction data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "qcTJzjrXYAqH"
      },
      "outputs": [],
      "source": [
        "from previous_chapters import (\n",
        "    calc_loss_loader,\n",
        "    train_model_simple\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnQ1hc7aWovu"
      },
      "source": [
        "Using the `calc_closs_loader`, we compute the initial training, validation, and test set losses before we start training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "np62R4grPePE",
        "outputId": "070844d3-dfcc-43c6-e7b6-99b0b545bdfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 4.167139339447021\n",
            "Validation loss: 4.050935745239258\n"
          ]
        }
      ],
      "source": [
        "model.to(device)\n",
        "\n",
        "torch.manual_seed(123)  # For reproducibility due to the shuffling in the data loader\n",
        "\n",
        "with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-XWwke1SfOU",
        "outputId": "30c9e703-48b6-4f43-a7e7-cd9ad21682d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ep 1 (Step 000000): Train loss 3.119, Val loss 3.069\n",
            "Ep 1 (Step 000005): Train loss 1.696, Val loss 1.570\n",
            "Ep 1 (Step 000010): Train loss 1.096, Val loss 1.164\n",
            "Ep 1 (Step 000015): Train loss 1.053, Val loss 1.083\n",
            "Ep 1 (Step 000020): Train loss 0.970, Val loss 1.038\n",
            "Ep 1 (Step 000025): Train loss 0.920, Val loss 1.002\n",
            "Ep 1 (Step 000030): Train loss 0.960, Val loss 0.978\n",
            "Ep 1 (Step 000035): Train loss 0.878, Val loss 0.951\n",
            "Ep 1 (Step 000040): Train loss 0.847, Val loss 0.943\n",
            "Ep 1 (Step 000045): Train loss 0.777, Val loss 0.925\n",
            "Ep 1 (Step 000050): Train loss 0.869, Val loss 0.911\n",
            "Ep 1 (Step 000055): Train loss 0.924, Val loss 0.893\n",
            "Ep 1 (Step 000060): Train loss 0.873, Val loss 0.878\n",
            "Ep 1 (Step 000065): Train loss 0.800, Val loss 0.867\n",
            "Ep 1 (Step 000070): Train loss 0.694, Val loss 0.860\n",
            "Ep 1 (Step 000075): Train loss 0.706, Val loss 0.856\n",
            "Ep 1 (Step 000080): Train loss 0.753, Val loss 0.847\n",
            "Ep 1 (Step 000085): Train loss 0.680, Val loss 0.836\n",
            "Ep 1 (Step 000090): Train loss 0.729, Val loss 0.827\n",
            "Ep 1 (Step 000095): Train loss 0.653, Val loss 0.821\n",
            "Ep 1 (Step 000100): Train loss 0.634, Val loss 0.808\n",
            "Ep 1 (Step 000105): Train loss 0.728, Val loss 0.803\n",
            "Ep 1 (Step 000110): Train loss 0.719, Val loss 0.799\n",
            "Ep 1 (Step 000115): Train loss 0.672, Val loss 0.796\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Input: The following is an instruction that describes a task.\n",
            "Ep 2 (Step 000120): Train loss 0.592, Val loss 0.790\n",
            "Ep 2 (Step 000125): Train loss 0.626, Val loss 0.801\n",
            "Ep 2 (Step 000130): Train loss 0.584, Val loss 0.788\n",
            "Ep 2 (Step 000135): Train loss 0.547, Val loss 0.791\n",
            "Ep 2 (Step 000140): Train loss 0.580, Val loss 0.789\n",
            "Ep 2 (Step 000145): Train loss 0.518, Val loss 0.785\n",
            "Ep 2 (Step 000150): Train loss 0.520, Val loss 0.780\n",
            "Ep 2 (Step 000155): Train loss 0.594, Val loss 0.784\n",
            "Ep 2 (Step 000160): Train loss 0.585, Val loss 0.785\n",
            "Ep 2 (Step 000165): Train loss 0.537, Val loss 0.781\n",
            "Ep 2 (Step 000170): Train loss 0.440, Val loss 0.775\n",
            "Ep 2 (Step 000175): Train loss 0.479, Val loss 0.769\n",
            "Ep 2 (Step 000180): Train loss 0.540, Val loss 0.760\n",
            "Ep 2 (Step 000185): Train loss 0.567, Val loss 0.757\n",
            "Ep 2 (Step 000190): Train loss 0.442, Val loss 0.742\n",
            "Ep 2 (Step 000195): Train loss 0.469, Val loss 0.729\n",
            "Ep 2 (Step 000200): Train loss 0.408, Val loss 0.728\n",
            "Ep 2 (Step 000205): Train loss 0.479, Val loss 0.724\n",
            "Ep 2 (Step 000210): Train loss 0.516, Val loss 0.724\n",
            "Ep 2 (Step 000215): Train loss 0.539, Val loss 0.733\n",
            "Ep 2 (Step 000220): Train loss 0.414, Val loss 0.738\n",
            "Ep 2 (Step 000225): Train loss 0.487, Val loss 0.738\n",
            "Ep 2 (Step 000230): Train loss 0.425, Val loss 0.742\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Input: What is the chemical symbol for carbon?  \n",
            "Ep 3 (Step 000235): Train loss 0.487, Val loss 0.736\n",
            "Ep 3 (Step 000240): Train loss 0.410, Val loss 0.749\n",
            "Ep 3 (Step 000245): Train loss 0.400, Val loss 0.754\n",
            "Ep 3 (Step 000250): Train loss 0.394, Val loss 0.737\n",
            "Ep 3 (Step 000255): Train loss 0.405, Val loss 0.735\n",
            "Ep 3 (Step 000260): Train loss 0.390, Val loss 0.735\n",
            "Ep 3 (Step 000265): Train loss 0.422, Val loss 0.735\n",
            "Ep 3 (Step 000270): Train loss 0.432, Val loss 0.739\n",
            "Ep 3 (Step 000275): Train loss 0.380, Val loss 0.741\n",
            "Ep 3 (Step 000280): Train loss 0.406, Val loss 0.750\n",
            "Ep 3 (Step 000285): Train loss 0.394, Val loss 0.752\n",
            "Ep 3 (Step 000290): Train loss 0.399, Val loss 0.756\n",
            "Ep 3 (Step 000295): Train loss 0.361, Val loss 0.756\n",
            "Ep 3 (Step 000300): Train loss 0.358, Val loss 0.742\n",
            "Ep 3 (Step 000305): Train loss 0.365, Val loss 0.740\n",
            "Ep 3 (Step 000310): Train loss 0.339, Val loss 0.742\n",
            "Ep 3 (Step 000315): Train loss 0.304, Val loss 0.738\n",
            "Ep 3 (Step 000320): Train loss 0.359, Val loss 0.737\n",
            "Ep 3 (Step 000325): Train loss 0.325, Val loss 0.741\n",
            "Ep 3 (Step 000330): Train loss 0.307, Val loss 0.748\n",
            "Ep 3 (Step 000335): Train loss 0.310, Val loss 0.754\n",
            "Ep 3 (Step 000340): Train loss 0.326, Val loss 0.741\n",
            "Ep 3 (Step 000345): Train loss 0.347, Val loss 0.730\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Input: What is the capital of the United Kingdom? \n",
            "Ep 4 (Step 000350): Train loss 0.312, Val loss 0.738\n",
            "Ep 4 (Step 000355): Train loss 0.287, Val loss 0.790\n",
            "Ep 4 (Step 000360): Train loss 0.301, Val loss 0.822\n",
            "Ep 4 (Step 000365): Train loss 0.311, Val loss 0.799\n",
            "Ep 4 (Step 000370): Train loss 0.380, Val loss 0.774\n",
            "Ep 4 (Step 000375): Train loss 0.316, Val loss 0.762\n",
            "Ep 4 (Step 000380): Train loss 0.271, Val loss 0.780\n",
            "Ep 4 (Step 000385): Train loss 0.312, Val loss 0.782\n",
            "Ep 4 (Step 000390): Train loss 0.272, Val loss 0.792\n",
            "Ep 4 (Step 000395): Train loss 0.265, Val loss 0.796\n",
            "Ep 4 (Step 000400): Train loss 0.272, Val loss 0.791\n",
            "Ep 4 (Step 000405): Train loss 0.312, Val loss 0.787\n",
            "Ep 4 (Step 000410): Train loss 0.250, Val loss 0.781\n",
            "Ep 4 (Step 000415): Train loss 0.263, Val loss 0.780\n",
            "Ep 4 (Step 000420): Train loss 0.256, Val loss 0.785\n",
            "Ep 4 (Step 000425): Train loss 0.247, Val loss 0.800\n",
            "Ep 4 (Step 000430): Train loss 0.264, Val loss 0.808\n",
            "Ep 4 (Step 000435): Train loss 0.263, Val loss 0.804\n",
            "Ep 4 (Step 000440): Train loss 0.255, Val loss 0.787\n",
            "Ep 4 (Step 000445): Train loss 0.260, Val loss 0.783\n",
            "Ep 4 (Step 000450): Train loss 0.243, Val loss 0.786\n",
            "Ep 4 (Step 000455): Train loss 0.251, Val loss 0.784\n",
            "Ep 4 (Step 000460): Train loss 0.262, Val loss 0.763\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom? \n",
            "Ep 5 (Step 000465): Train loss 0.275, Val loss 0.752\n",
            "Ep 5 (Step 000470): Train loss 0.232, Val loss 0.777\n",
            "Ep 5 (Step 000475): Train loss 0.244, Val loss 0.804\n",
            "Ep 5 (Step 000480): Train loss 0.228, Val loss 0.808\n",
            "Ep 5 (Step 000485): Train loss 0.239, Val loss 0.805\n",
            "Ep 5 (Step 000490): Train loss 0.242, Val loss 0.808\n",
            "Ep 5 (Step 000495): Train loss 0.243, Val loss 0.805\n",
            "Ep 5 (Step 000500): Train loss 0.226, Val loss 0.803\n",
            "Ep 5 (Step 000505): Train loss 0.253, Val loss 0.815\n",
            "Ep 5 (Step 000510): Train loss 0.224, Val loss 0.813\n",
            "Ep 5 (Step 000515): Train loss 0.207, Val loss 0.815\n",
            "Ep 5 (Step 000520): Train loss 0.237, Val loss 0.821\n",
            "Ep 5 (Step 000525): Train loss 0.261, Val loss 0.824\n",
            "Ep 5 (Step 000530): Train loss 0.227, Val loss 0.815\n",
            "Ep 5 (Step 000535): Train loss 0.199, Val loss 0.801\n",
            "Ep 5 (Step 000540): Train loss 0.228, Val loss 0.804\n",
            "Ep 5 (Step 000545): Train loss 0.224, Val loss 0.814\n",
            "Ep 5 (Step 000550): Train loss 0.230, Val loss 0.815\n",
            "Ep 5 (Step 000555): Train loss 0.225, Val loss 0.803\n",
            "Ep 5 (Step 000560): Train loss 0.218, Val loss 0.797\n",
            "Ep 5 (Step 000565): Train loss 0.199, Val loss 0.797\n",
            "Ep 5 (Step 000570): Train loss 0.211, Val loss 0.806\n",
            "Ep 5 (Step 000575): Train loss 0.215, Val loss 0.810\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the chemical formula for sodium carbonate?\n",
            "Training completed in 3.65 minutes.\n"
          ]
        }
      ],
      "source": [
        "# takes a while to run on CPU\n",
        "\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKQ9jddpVYLw"
      },
      "outputs": [],
      "source": [
        "# Save the model in case we want to reuse the model later\n",
        "torch.save(model.state_dict(), \"instruct_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "GarStmfHSfQ5",
        "outputId": "cfe76f59-27f6-4d16-da02-d26b15c781a4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from previous_chapters import plot_losses\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qnzLQ8lWfbU"
      },
      "source": [
        "### Using the LLM to follow instructions\n",
        "\n",
        "Let's use the finetuned GPT model in action."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYLEUOHvWhxY",
        "outputId": "20d7e452-e933-4717-fe8a-891ded9f7fe2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the newly trained model\n",
        "\n",
        "# when using server\n",
        "model_state_dict = torch.load(\"../../../instruct_model.pth\", map_location=device)\n",
        "# when using colab\n",
        "#model_state_dict = torch.load(\"instruct_model.pth\")\n",
        "model.load_state_dict(model_state_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-b90h_LSzKi"
      },
      "source": [
        "### Run instruction model on test dataset and extract responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOX5DJCTSfTZ"
      },
      "outputs": [],
      "source": [
        "def extract_response(response):\n",
        "    return response[response.find(\"\\n### Response\")+len(\"\\n### Response:\")+1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Oe32RlgSfWF",
        "outputId": "eb4ede7b-426f-4376-cce4-9ed11935b72f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Classify each sentence as either declarative, interrogative, imperative, or exclamatory.\n",
            "\n",
            "### Input:\n",
            "Please open the door.\n",
            "\n",
            "Correct response:\n",
            ">> The classification of the sentence 'Please open the door.' is imperative.\n",
            "\n",
            "Model response:\n",
            ">> Clarity is a function of time.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Rewrite the sentence to use a negative adverb.\n",
            "\n",
            "### Input:\n",
            "She always remembers to call.\n",
            "\n",
            "Correct response:\n",
            ">> She never forgets to call.\n",
            "\n",
            "Model response:\n",
            ">> She always calls.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert 50 miles per hour to kilometers per hour.\n",
            "\n",
            "Correct response:\n",
            ">> 50 miles per hour is approximately 80.47 kilometers per hour.\n",
            "\n",
            "Model response:\n",
            ">> 50 miles per hour is approximately 32.07 kilometers per hour.\n",
            "-------------------------------------\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "# last three samples from test dataset\n",
        "for entry in test_data[-3:]:\n",
        "\n",
        "    # prepare input\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    # run inference\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "\n",
        "    # post process output\n",
        "    response = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = extract_response(response)\n",
        "\n",
        "    # print output\n",
        "    print(input_text)\n",
        "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
        "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
        "    print(\"-------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWNh-bTGjJ4X"
      },
      "source": [
        "### Run instruction model on custom inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5zwksbsZrgN"
      },
      "outputs": [],
      "source": [
        "def run_instruction_model(instruction_text, input_text):\n",
        "\n",
        "  # prepare inputs\n",
        "  input_text = format_input({'instruction': instruction_text, 'input': input_text})\n",
        "\n",
        "  # model inference\n",
        "  token_ids = generate(\n",
        "      model=model,\n",
        "      idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "      max_new_tokens=256,\n",
        "      context_size=BASE_CONFIG[\"context_length\"],\n",
        "      eos_id=50256\n",
        "  )\n",
        "\n",
        "  # post process output\n",
        "  response = token_ids_to_text(token_ids, tokenizer)\n",
        "  response_text = extract_response(response)\n",
        "\n",
        "  # print output and return the output\n",
        "  print(input_text)\n",
        "  print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
        "  print(\"-------------------------------------\")\n",
        "  return response_text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5CxBSxRbq-0",
        "outputId": "04e7fb04-8b8e-4bc8-ea2c-5373e4aa2b0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Rewrite the sentence using a simile.\n",
            "\n",
            "### Input:\n",
            "The car is very fast.\n",
            "\n",
            "Model response:\n",
            ">> The car is as fast as a cheetah.\n",
            "-------------------------------------\n"
          ]
        }
      ],
      "source": [
        "instruction = \"Rewrite the sentence using a simile.\"\n",
        "input = \"The car is very fast.\"\n",
        "\n",
        "output_text = run_instruction_model(instruction, input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTWUzFUGPeUn",
        "outputId": "35bad282-7cd6-427f-bd1d-28fc5c816549"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Is the following text a spam?\n",
            "\n",
            "### Input:\n",
            "You are a winner you have been specially selected to receive $1000 cash or a $2000 award.\n",
            "\n",
            "Model response:\n",
            ">> The text was a spam.\n",
            "-------------------------------------\n"
          ]
        }
      ],
      "source": [
        "instruction_2 = \"Is the following text a spam?\"\n",
        "input_2 = \"You are a winner you have been specially selected to receive $1000 cash or a $2000 award.\"\n",
        "\n",
        "output_text2 = run_instruction_model(instruction_2, input_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKwhY-LKcsSd",
        "outputId": "2e25e0f9-04a3-4f5a-8675-11b72576ccb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Translate into French.\n",
            "\n",
            "### Input:\n",
            "Hello, How are you?\n",
            "\n",
            "Model response:\n",
            ">> I am in France.\n",
            "-------------------------------------\n"
          ]
        }
      ],
      "source": [
        "instruction_3 = \"Translate into French.\"\n",
        "input_3 = \"Hello, How are you?\"\n",
        "\n",
        "output_text3 = run_instruction_model(instruction_3, input_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb_XxvhFdnbP",
        "outputId": "c6e5e37f-1e3a-4d4a-df3b-a739d05b4dbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert 3 meters to centimeters.\n",
            "\n",
            "Model response:\n",
            ">> 3 meters is 300 centimeters.\n",
            "-------------------------------------\n"
          ]
        }
      ],
      "source": [
        "instruction_4 = \"Convert 3 meters to centimeters.\"\n",
        "input_4 = \"\"\n",
        "\n",
        "output_text3 = run_instruction_model(instruction_4, input_4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2wMJuE8YAqQ"
      },
      "outputs": [],
      "source": [
        "# cleanup\n",
        "!rm -rf /home/haszun/june-20/LLMs-from-scratch/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4qgSqsmB8oU"
      },
      "source": [
        "## 3. Learning resources\n",
        "* [Intro to Large Language Models](https://youtu.be/zjkBMFhNj_g?si=bIVqXiQratJdqvhj)\n",
        "* [Understanding Large Language Models](https://magazine.sebastianraschka.com/p/understanding-large-language-models)\n",
        "* [QLoRA is all you need (Fast and lightweight model fine-tuning)](https://youtu.be/J_3hDqSvpmg?si=b0j8O2puV42z18UL)\n",
        "* [Parameter-efficient Finetuning with LoRA](https://github.com/rasbt/LLMs-from-scratch/blob/main/appendix-E/01_main-chapter-code/appendix-E.ipynb)\n",
        "* [QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314)\n",
        "* [Run Mixtral-8x7B models in Colab or consumer desktops](https://github.com/dvmazur/mixtral-offloading)\n",
        "\n",
        "### Acknowledgements\n",
        "\n",
        "This repository was built using [Implementing a ChatGPT-like LLM in PyTorch from scratch, step by step](https://github.com/rasbt/LLMs-from-scratch)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0R30bm_MKtp",
        "outputId": "6ba2be84-3f38-4a47-b84a-1782ccd3c91a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The End.\n"
          ]
        }
      ],
      "source": [
        "print(\"The End.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miQsnhH_YAqR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "M4qgSqsmB8oU"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}