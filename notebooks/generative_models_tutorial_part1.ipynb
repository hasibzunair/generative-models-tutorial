{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEYg5RqnNdHk"
   },
   "source": [
    "# Building and applying Generative Models using PyTorch\n",
    "\n",
    "**Author:** [Hasib Zunair](https://hasibzunair.github.io/)<br>\n",
    "**Date created:** 2024/03/20<br>\n",
    "**Last modified:** 2024/06/10<br>\n",
    "\n",
    "**Description:** This tutorial deep dives into generative models in the context of text generation. We begin by importing the main Python/PyTorch modules for building generative models. Then we look at how to use recent cutting-edge large language models (LLMs) like GPT to build and train specialized models on a dataset for text classification. Finally, we also show to build and train generalist models to perform a variety of tasks. After being introduced to generative models and how to apply them in PyTorch, participants can apply what they have learned on their own datasets and tasks.\n",
    "\n",
    "**Learning Objectives:**\n",
    "At the end of this tutorial on generative models, participants will be able to:\n",
    "\n",
    "* describe how to import the main Python/PyTorch modules for building generative models\n",
    "* build and train large language models (LLMs) for specialized and generalist tasks\n",
    "* implement generative models in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UiSHr_2ZK_HN"
   },
   "source": [
    "## 0. Get materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "neoj8Gp4LDDy",
    "outputId": "81f65443-12ec-4966-e850-4d4f048f46ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'LLMs-from-scratch'...\n",
      "remote: Enumerating objects: 3092, done.\u001b[K\n",
      "remote: Counting objects: 100% (751/751), done.\u001b[K\n",
      "remote: Compressing objects: 100% (142/142), done.\u001b[K\n",
      "remote: Total 3092 (delta 634), reused 646 (delta 609), pack-reused 2341\u001b[K\n",
      "Receiving objects: 100% (3092/3092), 9.38 MiB | 11.83 MiB/s, done.\n",
      "Resolving deltas: 100% (1913/1913), done.\n",
      "/home/haszun/june-20/LLMs-from-scratch/ch06/01_main-chapter-code\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/rasbt/LLMs-from-scratch\n",
    "%cd LLMs-from-scratch/ch06/01_main-chapter-code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SQ6jZLQtfpCH",
    "outputId": "675356fa-03e3-482e-a750-ae020304499f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.26.0->tiktoken) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.26.0->tiktoken) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.26.0->tiktoken) (2020.6.20)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow==2.15.0 in /home/haszun/.local/lib/python3.10/site-packages (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/haszun/.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/haszun/.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /home/haszun/.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/haszun/.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/haszun/.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/haszun/.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/haszun/.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /home/haszun/.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.24.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/haszun/.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/haszun/.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (4.25.3)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow==2.15.0) (59.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow==2.15.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/haszun/.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (4.10.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /home/haszun/.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/haszun/.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.37.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/haszun/.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.64.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /home/haszun/.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /home/haszun/.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /home/haszun/.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/haszun/.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.29.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /home/haszun/.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/haszun/.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/haszun/.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/haszun/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.2.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/haszun/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2020.6.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/haszun/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.1.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.8)\n",
      "matplotlib version: 3.5.1\n",
      "numpy version: 1.24.4\n",
      "tiktoken version: 0.6.0\n",
      "torch version: 1.11.0\n",
      "tensorflow version: 2.15.0\n",
      "pandas version: 2.2.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "!pip install tiktoken\n",
    "!pip install tensorflow==2.15.0\n",
    "\n",
    "pkgs = [\"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"tiktoken\",\n",
    "        \"torch\",\n",
    "        \"tensorflow\", # For OpenAI's pretrained weights\n",
    "        \"pandas\"      # Dataset loading\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TLwvJSA_JmHv"
   },
   "source": [
    "## 1. Finetuning a Large Language Model (LLM) for Text Classification\n",
    "\n",
    "This is also called classification finetuning. \n",
    "\n",
    "Classification finetuned models are **specialized models** in the sense that it can **only predict classes it has seen during training**. It is similar to training a dog and cat image classifier done in [this notebook](https://github.com/hasibzunair/intro-ml-tutorial/blob/main/tensorflow_tutorial.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zlHTIWOMawG"
   },
   "source": [
    "### Prepare the dataset\n",
    "\n",
    "* Download, inspect, preprocess and create data loaders\n",
    "* We use a dataset consisting of spam and non-spam text messages to finetune the LLM to classify them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j1nDuheaHyNX",
    "outputId": "26c06ef6-f20c-4119-ea35-16d2a51f2b3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved as sms_spam_collection/SMSSpamCollection.tsv\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "9nBPRSU4HyQR",
    "outputId": "400343a2-8319-4713-ff4e-5a29b1952cd9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eo33VWyNNXi6",
    "outputId": "7b71d83f-a1b6-4c0c-9909-1c3b63ba5621"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts()) # ham (\"not spam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xdweLaNHNXlN",
    "outputId": "b256a2f2-6469-427e-fd4a-fae581229540"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# To keep it simple, we subsample (undersample) the dataset so that it contains 747 instances from each class\n",
    "\n",
    "def create_balanced_dataset(df):\n",
    "\n",
    "    # Count the instances of \"spam\"\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "\n",
    "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "\n",
    "    # Combine ham \"subset\" with \"spam\"\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YpEKL_k0NXn3"
   },
   "outputs": [],
   "source": [
    "# Next, we change the string class labels \"ham\" and \"spam\" into integer class labels 0 and 1\n",
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvCAI5UKO71E"
   },
   "source": [
    "Let's now define a function that randomly divides the dataset into a training, validation, and test subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "RzyxgGMcNXqN"
   },
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    # Shuffle the entire DataFrame\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # Calculate split indices\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # Split the DataFrame\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "# Test size is implied to be 0.2 as the remainder\n",
    "\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eOFc6yKDPH4x"
   },
   "source": [
    "### Create data loaders\n",
    "\n",
    "Text messages have different lengths, to combine multiple training examples in a batch, we pad all messages to the length of the longest message in the dataset or batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_KUZWg0RNXsb",
    "outputId": "3cbe2afe-8eb4-4788-d59c-05b3c8ebb65d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNQ6ghOcPo8P"
   },
   "source": [
    "The SpamDataset class below identifies the longest sequence in the training dataset and adds the padding token to the others to match that sequence length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4c5dL53QNXuy"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # Truncate sequences if they are longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # Pad sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ABXvlJjhNXxT",
    "outputId": "8f79e2b1-0a4d-48cc-c950-20416d82e203"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "pzdr4axtNXzp"
   },
   "outputs": [],
   "source": [
    "# We also pad the validation and test set to the longest training sequence\n",
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QdwDUTo0P_3Q"
   },
   "source": [
    "Next, we use the dataset to instantiate the data loaders, which is similar to creating the data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "q_UBRet-NX11"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k27-6sV2NX4P",
    "outputId": "225b7bbe-1366-40ed-d9dd-2ac1b506183a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "# iterate through the data loaders and ensure that the batches contain 8 training examples each, where each training example consists of 120 tokens\n",
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jgpSAncANX7H",
    "outputId": "47899772-d336-4e6b-c94d-2bbb9ab79360"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "# Lastly, let's print the total number of batches in each dataset\n",
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0eClOGVtQSiM"
   },
   "source": [
    "### Initialize a LLM with pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "hzlhjfDcQLZX"
   },
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8rrxDm9CQLca",
    "outputId": "9290241a-ea96-4bf8-f06e-4bbceacd2e2b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-13 15:17:42.126046: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-13 15:17:42.166413: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-13 15:17:42.166441: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-13 15:17:42.167699: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-13 15:17:42.174288: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-13 15:17:42.175128: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-13 15:17:44.733988: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 15.7kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 5.64MiB/s]\n",
      "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 18.9kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [00:48<00:00, 10.3MiB/s] \n",
      "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 1.01MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 3.23MiB/s]\n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 3.13MiB/s]\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1FTegrmeQvCq"
   },
   "source": [
    "To ensure that the model was loaded corrected, let's double-check that it generates coherent text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zlwe4muPQLhC",
    "outputId": "0bba259f-4972-4e39-b23d-f9186f3e2828"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am taking a tutorial on generative models at Ericsson and I am going to show you how to use them to create a generative model.\n",
      "\n",
      "The first thing you need to do is to create a\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    generate_text_simple,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "\n",
    "text_1 = \"I am taking a tutorial on generative models at Ericsson and\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=30,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wh7HCMUfRTiP"
   },
   "source": [
    "Before we finetune the model as a classifier, let's see if the model can perhaps already classify spam messages via prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lHFhS4q8QLl_",
    "outputId": "15b8d9b8-dd4e-47c9-82da-4a5c186de25a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrHZnobFRe9L"
   },
   "source": [
    "We can see the model is not very good at following instructions. This is expected since it has only been pretrained and not **instruction finetuned**, which we will do in the next section!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9z-K01UHRn88"
   },
   "source": [
    "### Adding a classification head\n",
    "\n",
    "Here we modify the pretrained LLM (GPT) to make it ready for classification finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yj09JxyAQLob",
    "outputId": "ad25fd98-02fc-4776-8615-1cca57355e29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# lets look at the current model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rw1yXIVmSYC5"
   },
   "source": [
    "Now, we want to replace and finetune the output layer, specifically it will have only **2 units**, where it represents the two classes (**spam** and **not spam**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "upDu6W4oQLqt"
   },
   "outputs": [],
   "source": [
    "# Freeze the model, make all layers non-trainable\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "HuV3KoZhSrOi"
   },
   "outputs": [],
   "source": [
    "# We replace output layer, which originally maps inputs to 50,257 dimensions (the size of the vocabulary)\n",
    "# Since we finetune the model for binary classification, we replace the output layer with 2 dimensions for (spam and not spam)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "M6oqztdvQLtB"
   },
   "outputs": [],
   "source": [
    "# We can only finetune the new output layer for good results. However, finetuning additional layers improve performance.\n",
    "\n",
    "# unfreeze last trransformer block\n",
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# unfreeze final layer normalization\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LZruIhqxQLvn",
    "outputId": "1159e7c2-05e9-41e4-e28d-2890fe1c8f06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n",
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "# Can still use this model for text generation\n",
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)\n",
    "\n",
    "# Will have 2 output dimensions instead of 50,257\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "# Since we fed the model a text sample with 4 input tokens, the output consists of 4 2-dimensional output vectors above\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33RA0FWpUXXh"
   },
   "source": [
    "### Calculating the classification loss and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBghwgk1UvVO"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/overview-3.webp?123\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ciBkG1kUz1C"
   },
   "source": [
    "Before explaining the loss calculation, let's have a brief look at how the model outputs are turned into class labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vo3-VimCUz33"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/class-argmax.webp\" width=1000px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4HntfdJfQL3R",
    "outputId": "8792e6af-732b-416a-c2a9-b220e534fe68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "# last row output (token)\n",
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0c_a39jVU8Y"
   },
   "source": [
    "We convert the outputs (logits) into probability scores via the `softmax` function and then obtain the index position of the largest probability value via the `argmax` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7qmZEuEGQL50",
    "outputId": "2542374b-6fe5-4baa-b1fa-04a94d061d75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1o5d_JuaQL8K",
    "outputId": "0429818c-b765-4b4b-dfe3-329d46d174f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "# Note that the softmax function is optional here, because the largest outputs correspond to the largest probability scores\n",
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6IpzMzmWYTO"
   },
   "source": [
    "We can apply this concept to calculate the so-called classification accuracy, which computes the percentage of correct predictions in a given dataset. To calculate the classification accuracy, we can apply the preceding `argmax`-based prediction code to all examples in a dataset and calculate the fraction of correct predictions as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "-bKUdDhQQL-k"
   },
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Alwwc5xyQMBH",
    "outputId": "8d83150b-99a7-49d2-86d8-9b5906b6466b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "# takes a while to run on CPU\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DilCljpCWn98"
   },
   "source": [
    "The prediction accuracies are not very good, since we haven't finetuned the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "-Mi19oqUQMDm"
   },
   "outputs": [],
   "source": [
    "# define loss, we will minimze the cross entropy when finetuning/training\n",
    "\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUwx3XSqXU0D"
   },
   "source": [
    "Using the `calc_closs_loader`, we compute the initial training, validation, and test set losses before we start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0fk-sGEoQMGe",
    "outputId": "6565fe74-20b0-4e6b-a955-609a23ac48a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.453\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # disable gradient tracking for efficiency, since not training yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yPD72OAXbDb"
   },
   "source": [
    "### Finetuning the model on supervised data\n",
    "\n",
    "We train the model to improve the loss values and consequently the classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "AvYLa7RBXeoS"
   },
   "outputs": [],
   "source": [
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter, tokenizer):\n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o-OI1b5mXeqt",
    "outputId": "74187eaf-0b3b-40a3-a444-fea8465a83e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.153, Val loss 2.392\n",
      "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
      "Ep 1 (Step 000100): Train loss 0.523, Val loss 0.557\n",
      "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
      "Ep 2 (Step 000150): Train loss 0.561, Val loss 0.489\n",
      "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.397\n",
      "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.353\n",
      "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
      "Ep 3 (Step 000300): Train loss 0.333, Val loss 0.320\n",
      "Ep 3 (Step 000350): Train loss 0.340, Val loss 0.306\n",
      "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
      "Training completed in 32.42 minutes.\n"
     ]
    }
   ],
   "source": [
    "# takes a while to run on CPU\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 3\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eDxW1u9mZM00"
   },
   "outputs": [],
   "source": [
    "# Save the model in case we want to reuse the model later\n",
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iAXcO0ZEYGDC"
   },
   "source": [
    "Plot the loss function for the training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4BTBAc2XetD"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "-vevSJ4aXevh",
    "outputId": "a3ba736c-b9b6-4dbb-ea99-e66ec74ae484"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqsvOBfZYPzb"
   },
   "source": [
    "Based on the downward slope, we see that the model learns well, train and validation losses are very close, the model does not overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "38ymRYHXYMqF",
    "outputId": "207b058a-ddb3-4f90-9d03-b8a1e9427db8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lMFPiMgkXex7",
    "outputId": "0495ef85-57d5-4e84-9f3a-607afcd501d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 87.21%\n",
      "Validation accuracy: 91.28%\n",
      "Test accuracy: 88.00%\n"
     ]
    }
   ],
   "source": [
    "# We can compute the training, validation, and test set performances over the complete dataset as follows below\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVrYzG_JYtoS"
   },
   "source": [
    "We can see that the training and test set performances are practically identical. However, based on the slightly lower test set performance, we can see that the model overfits the training data to a very small degree, as well as the validation data that has been used for tweaking some of the hyperparameters, such as the learning rate. This is normal, however, and this gap could potentially be further reduced by increasing the model's dropout rate (`drop_rate`) or the `weight_decay` in the optimizer setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7lb2vpHIYz5l"
   },
   "source": [
    "### Using the LLM as a spam classifier\n",
    "\n",
    "Let's use the finetuned GPT model!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fFcptBKXZWdA",
    "outputId": "7dfdc99d-9336-440c-f4c8-859df43c1f23"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the newly trained model\n",
    "\n",
    "# when using server\n",
    "model_state_dict = torch.load(\"/home/haszun/june-20/review_classifier.pth\")\n",
    "# when using colab\n",
    "#model_state_dict = torch.load(\"review_classifier.pth\")\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "rXRnwQSoXe0b"
   },
   "outputs": [],
   "source": [
    "# take in new text\n",
    "# preprocess\n",
    "# run preprocessed input through the model\n",
    "# take the predicted integer class label from the model and return the corresponding class name\n",
    "\n",
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[1]\n",
    "\n",
    "    # Truncate sequences if they too long\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\n",
    "    # Pad sequences to the longest sequence\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Return the classified result\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kiYkHHEOXe2w",
    "outputId": "ee1ce8fd-d5fc-4c04-f091-284cb590d727"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"Reminder: You have not downloaded the content you have already paid for.\"\n",
    "    \"Goto http://doit. mymoby. tv/ to collect your content.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ONitBWryXe5W",
    "outputId": "8a8550b8-109d-41a7-a902-764593f8dcca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Ericsson shapes the future of mobile broadband internet communications \"\n",
    "    \"through its technology leadership.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup\n",
    "!rm -rf /home/haszun/june-20/LLMs-from-scratch/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to `generative_models_tutorial_part2.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1P9cEkJufp43",
    "outputId": "4842d911-3054-4511-fbaf-60de7a0dc2b1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../../LLMs-from-scratch/ch07/01_main-chapter-code/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MreyRpRNNBOI"
   },
   "source": [
    "### Prepare dataset\n",
    "\n",
    "Download the instruction dataset. It consists of instruction, input and output text pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7fcJFED7LKeq",
    "outputId": "22f0dfbc-2690-476d-b4fb-b7df4926b71f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode('utf-8')\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9CkROeJNfof"
   },
   "source": [
    "Each item in the `data` list we loaded from the JSON file above is a dictionary in the following form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-4On2iqLKhV",
    "outputId": "2f15a647-da8b-4873-ef2b-3afb5ea97593"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      "\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\\n\", data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0CCRg2RrNYbs",
    "outputId": "f305ab63-d116-44f7-92c1-755b8b31d6ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another example entry:\n",
      "\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Another example entry:\\n\\n\", data[999])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CyNsJ3R0Nq87"
   },
   "source": [
    "We use Alpaca-style prompt formatting, which was the original prompt template for instruction finetuning. For more details, see https://crfm.stanford.edu/2023/03/13/alpaca.html.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "rbdV5TsBLKkE"
   },
   "outputs": [],
   "source": [
    "# format the input that we will pass as input to the LLM\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J0WpbkUZLKmC",
    "outputId": "4c5935a2-c9d8-4d71-e8fa-37971ec02c0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "# A formatted response with input field looks like as shown below\n",
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aVOnXNpDLKoH",
    "outputId": "4395a025-46dd-479b-8387-5f9c27c59b3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "# Below is a formatted response without input field\n",
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "c9yTuQKmPA8Y"
   },
   "outputs": [],
   "source": [
    "# Split to train, val and test\n",
    "train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "test_portion = int(len(data) * 0.1)   # 10% for testing\n",
    "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fcowq7GaLKqh",
    "outputId": "09d06f2c-8f18-4899-db60-ad606d472a93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZS1b2HLPLbB"
   },
   "source": [
    "### Create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "dBBXXPKSLKs9"
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "POGQKfS4LKvr"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QzugulD-LKyV",
    "outputId": "314784ba-4d79-43a4-9851-64d3b1496d71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "bvyh1S5BPd4v"
   },
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs and targets\n",
    "    inputs_lst, targets_lst = [], []\n",
    "    for item in batch:\n",
    "        # Add an <|endoftext|> token\n",
    "        item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = item + [pad_token_id] * (batch_max_length - len(item))\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "\n",
    "        # Replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        # Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tWchoV4YPd7O",
    "outputId": "8781fe9b-4ef7-4b0e-f5b9-a6fe02c9a40c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "customized_collate_fn = partial(custom_collate_fn, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "VX0Hkw4BPd9n"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "af6BFqPNP6li",
    "outputId": "7eadf623-d3ef-407c-d7d4-35eb510542c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kYXzUKNWPeCP",
    "outputId": "dbb88a9a-d680-43f6-b575-4a2717323b60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21106, 318, 281, 12064, 326, 8477, 257, 4876, 13, 19430, 257, 2882, 326, 20431, 32543, 262, 2581, 13, 198, 198, 21017, 46486, 25, 198, 30003, 6525, 262, 6827, 1262, 257, 985, 576, 13, 198, 198, 21017, 23412, 25, 198, 464, 5156, 318, 845, 13779, 13, 198, 198, 21017, 18261, 25, 198, 464, 5156, 318, 355, 13779, 355, 257, 4936, 13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, "
     ]
    }
   ],
   "source": [
    "for i in x[0]:\n",
    "    print(i.item(), end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0VRCWUx4PeEy",
    "outputId": "0001d029-6e33-49b8-8d9e-bdd104696c59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318, 281, 12064, 326, 8477, 257, 4876, 13, 19430, 257, 2882, 326, 20431, 32543, 262, 2581, 13, 198, 198, 21017, 46486, 25, 198, 30003, 6525, 262, 6827, 1262, 257, 985, 576, 13, 198, 198, 21017, 23412, 25, 198, 464, 5156, 318, 845, 13779, 13, 198, 198, 21017, 18261, 25, 198, 464, 5156, 318, 355, 13779, 355, 257, 4936, 13, 50256, -100, -100, -100, -100, -100, -100, -100, -100, -100, "
     ]
    }
   ],
   "source": [
    "for i in y[0]:\n",
    "    print(i.item(), end=\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NDJS2C-QC26"
   },
   "source": [
    "### Initialize a LLM with pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SnGj-R77PeHM",
    "outputId": "100d846b-a7f1-490f-ef6d-8c8797526f3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWX8phKfhYxr"
   },
   "source": [
    "To ensure that the model was loaded corrected, let's double-check that it generates coherent text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import (\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float('-inf')).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zyPxSZeJPeJy",
    "outputId": "0580c08b-7cb3-4183-e8d8-9721cba2bc09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(format_input(val_data[0]), tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkmJKdY-RRWY"
   },
   "source": [
    "### Finetuning the LLM on instruction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from previous_chapters import (\n",
    "#     calc_loss_loader,\n",
    "#     train_model_simple\n",
    "# )\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()  # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()  # Calculate loss gradients\n",
    "            optimizer.step()  # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lnQ1hc7aWovu"
   },
   "source": [
    "Using the `calc_closs_loader`, we compute the initial training, validation, and test set losses before we start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "np62R4grPePE",
    "outputId": "32715d7b-cf35-4336-8f63-009d84aa181f"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_612877/2724107388.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_612877/3555500722.py\u001b[0m in \u001b[0;36mcalc_loss_loader\u001b[0;34m(data_loader, model, device, num_batches)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_612877/4059873788.py\u001b[0m in \u001b[0;36mcalc_loss_batch\u001b[0;34m(input_batch, target_batch, model, device)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Logits of last output token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2994\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2995\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2996\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)  # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9-XWwke1SfOU",
    "outputId": "30c9e703-48b6-4f43-a7e7-cd9ad21682d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 3.119, Val loss 3.069\n",
      "Ep 1 (Step 000005): Train loss 1.696, Val loss 1.570\n",
      "Ep 1 (Step 000010): Train loss 1.096, Val loss 1.164\n",
      "Ep 1 (Step 000015): Train loss 1.053, Val loss 1.083\n",
      "Ep 1 (Step 000020): Train loss 0.970, Val loss 1.038\n",
      "Ep 1 (Step 000025): Train loss 0.920, Val loss 1.002\n",
      "Ep 1 (Step 000030): Train loss 0.960, Val loss 0.978\n",
      "Ep 1 (Step 000035): Train loss 0.878, Val loss 0.951\n",
      "Ep 1 (Step 000040): Train loss 0.847, Val loss 0.943\n",
      "Ep 1 (Step 000045): Train loss 0.777, Val loss 0.925\n",
      "Ep 1 (Step 000050): Train loss 0.869, Val loss 0.911\n",
      "Ep 1 (Step 000055): Train loss 0.924, Val loss 0.893\n",
      "Ep 1 (Step 000060): Train loss 0.873, Val loss 0.878\n",
      "Ep 1 (Step 000065): Train loss 0.800, Val loss 0.867\n",
      "Ep 1 (Step 000070): Train loss 0.694, Val loss 0.860\n",
      "Ep 1 (Step 000075): Train loss 0.706, Val loss 0.856\n",
      "Ep 1 (Step 000080): Train loss 0.753, Val loss 0.847\n",
      "Ep 1 (Step 000085): Train loss 0.680, Val loss 0.836\n",
      "Ep 1 (Step 000090): Train loss 0.729, Val loss 0.827\n",
      "Ep 1 (Step 000095): Train loss 0.653, Val loss 0.821\n",
      "Ep 1 (Step 000100): Train loss 0.634, Val loss 0.808\n",
      "Ep 1 (Step 000105): Train loss 0.728, Val loss 0.803\n",
      "Ep 1 (Step 000110): Train loss 0.719, Val loss 0.799\n",
      "Ep 1 (Step 000115): Train loss 0.672, Val loss 0.796\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Input: The following is an instruction that describes a task.\n",
      "Ep 2 (Step 000120): Train loss 0.592, Val loss 0.790\n",
      "Ep 2 (Step 000125): Train loss 0.626, Val loss 0.801\n",
      "Ep 2 (Step 000130): Train loss 0.584, Val loss 0.788\n",
      "Ep 2 (Step 000135): Train loss 0.547, Val loss 0.791\n",
      "Ep 2 (Step 000140): Train loss 0.580, Val loss 0.789\n",
      "Ep 2 (Step 000145): Train loss 0.518, Val loss 0.785\n",
      "Ep 2 (Step 000150): Train loss 0.520, Val loss 0.780\n",
      "Ep 2 (Step 000155): Train loss 0.594, Val loss 0.784\n",
      "Ep 2 (Step 000160): Train loss 0.585, Val loss 0.785\n",
      "Ep 2 (Step 000165): Train loss 0.537, Val loss 0.781\n",
      "Ep 2 (Step 000170): Train loss 0.440, Val loss 0.775\n",
      "Ep 2 (Step 000175): Train loss 0.479, Val loss 0.769\n",
      "Ep 2 (Step 000180): Train loss 0.540, Val loss 0.760\n",
      "Ep 2 (Step 000185): Train loss 0.567, Val loss 0.757\n",
      "Ep 2 (Step 000190): Train loss 0.442, Val loss 0.742\n",
      "Ep 2 (Step 000195): Train loss 0.469, Val loss 0.729\n",
      "Ep 2 (Step 000200): Train loss 0.408, Val loss 0.728\n",
      "Ep 2 (Step 000205): Train loss 0.479, Val loss 0.724\n",
      "Ep 2 (Step 000210): Train loss 0.516, Val loss 0.724\n",
      "Ep 2 (Step 000215): Train loss 0.539, Val loss 0.733\n",
      "Ep 2 (Step 000220): Train loss 0.414, Val loss 0.738\n",
      "Ep 2 (Step 000225): Train loss 0.487, Val loss 0.738\n",
      "Ep 2 (Step 000230): Train loss 0.425, Val loss 0.742\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Input: What is the chemical symbol for carbon?  \n",
      "Ep 3 (Step 000235): Train loss 0.487, Val loss 0.736\n",
      "Ep 3 (Step 000240): Train loss 0.410, Val loss 0.749\n",
      "Ep 3 (Step 000245): Train loss 0.400, Val loss 0.754\n",
      "Ep 3 (Step 000250): Train loss 0.394, Val loss 0.737\n",
      "Ep 3 (Step 000255): Train loss 0.405, Val loss 0.735\n",
      "Ep 3 (Step 000260): Train loss 0.390, Val loss 0.735\n",
      "Ep 3 (Step 000265): Train loss 0.422, Val loss 0.735\n",
      "Ep 3 (Step 000270): Train loss 0.432, Val loss 0.739\n",
      "Ep 3 (Step 000275): Train loss 0.380, Val loss 0.741\n",
      "Ep 3 (Step 000280): Train loss 0.406, Val loss 0.750\n",
      "Ep 3 (Step 000285): Train loss 0.394, Val loss 0.752\n",
      "Ep 3 (Step 000290): Train loss 0.399, Val loss 0.756\n",
      "Ep 3 (Step 000295): Train loss 0.361, Val loss 0.756\n",
      "Ep 3 (Step 000300): Train loss 0.358, Val loss 0.742\n",
      "Ep 3 (Step 000305): Train loss 0.365, Val loss 0.740\n",
      "Ep 3 (Step 000310): Train loss 0.339, Val loss 0.742\n",
      "Ep 3 (Step 000315): Train loss 0.304, Val loss 0.738\n",
      "Ep 3 (Step 000320): Train loss 0.359, Val loss 0.737\n",
      "Ep 3 (Step 000325): Train loss 0.325, Val loss 0.741\n",
      "Ep 3 (Step 000330): Train loss 0.307, Val loss 0.748\n",
      "Ep 3 (Step 000335): Train loss 0.310, Val loss 0.754\n",
      "Ep 3 (Step 000340): Train loss 0.326, Val loss 0.741\n",
      "Ep 3 (Step 000345): Train loss 0.347, Val loss 0.730\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Input: What is the capital of the United Kingdom? \n",
      "Ep 4 (Step 000350): Train loss 0.312, Val loss 0.738\n",
      "Ep 4 (Step 000355): Train loss 0.287, Val loss 0.790\n",
      "Ep 4 (Step 000360): Train loss 0.301, Val loss 0.822\n",
      "Ep 4 (Step 000365): Train loss 0.311, Val loss 0.799\n",
      "Ep 4 (Step 000370): Train loss 0.380, Val loss 0.774\n",
      "Ep 4 (Step 000375): Train loss 0.316, Val loss 0.762\n",
      "Ep 4 (Step 000380): Train loss 0.271, Val loss 0.780\n",
      "Ep 4 (Step 000385): Train loss 0.312, Val loss 0.782\n",
      "Ep 4 (Step 000390): Train loss 0.272, Val loss 0.792\n",
      "Ep 4 (Step 000395): Train loss 0.265, Val loss 0.796\n",
      "Ep 4 (Step 000400): Train loss 0.272, Val loss 0.791\n",
      "Ep 4 (Step 000405): Train loss 0.312, Val loss 0.787\n",
      "Ep 4 (Step 000410): Train loss 0.250, Val loss 0.781\n",
      "Ep 4 (Step 000415): Train loss 0.263, Val loss 0.780\n",
      "Ep 4 (Step 000420): Train loss 0.256, Val loss 0.785\n",
      "Ep 4 (Step 000425): Train loss 0.247, Val loss 0.800\n",
      "Ep 4 (Step 000430): Train loss 0.264, Val loss 0.808\n",
      "Ep 4 (Step 000435): Train loss 0.263, Val loss 0.804\n",
      "Ep 4 (Step 000440): Train loss 0.255, Val loss 0.787\n",
      "Ep 4 (Step 000445): Train loss 0.260, Val loss 0.783\n",
      "Ep 4 (Step 000450): Train loss 0.243, Val loss 0.786\n",
      "Ep 4 (Step 000455): Train loss 0.251, Val loss 0.784\n",
      "Ep 4 (Step 000460): Train loss 0.262, Val loss 0.763\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom? \n",
      "Ep 5 (Step 000465): Train loss 0.275, Val loss 0.752\n",
      "Ep 5 (Step 000470): Train loss 0.232, Val loss 0.777\n",
      "Ep 5 (Step 000475): Train loss 0.244, Val loss 0.804\n",
      "Ep 5 (Step 000480): Train loss 0.228, Val loss 0.808\n",
      "Ep 5 (Step 000485): Train loss 0.239, Val loss 0.805\n",
      "Ep 5 (Step 000490): Train loss 0.242, Val loss 0.808\n",
      "Ep 5 (Step 000495): Train loss 0.243, Val loss 0.805\n",
      "Ep 5 (Step 000500): Train loss 0.226, Val loss 0.803\n",
      "Ep 5 (Step 000505): Train loss 0.253, Val loss 0.815\n",
      "Ep 5 (Step 000510): Train loss 0.224, Val loss 0.813\n",
      "Ep 5 (Step 000515): Train loss 0.207, Val loss 0.815\n",
      "Ep 5 (Step 000520): Train loss 0.237, Val loss 0.821\n",
      "Ep 5 (Step 000525): Train loss 0.261, Val loss 0.824\n",
      "Ep 5 (Step 000530): Train loss 0.227, Val loss 0.815\n",
      "Ep 5 (Step 000535): Train loss 0.199, Val loss 0.801\n",
      "Ep 5 (Step 000540): Train loss 0.228, Val loss 0.804\n",
      "Ep 5 (Step 000545): Train loss 0.224, Val loss 0.814\n",
      "Ep 5 (Step 000550): Train loss 0.230, Val loss 0.815\n",
      "Ep 5 (Step 000555): Train loss 0.225, Val loss 0.803\n",
      "Ep 5 (Step 000560): Train loss 0.218, Val loss 0.797\n",
      "Ep 5 (Step 000565): Train loss 0.199, Val loss 0.797\n",
      "Ep 5 (Step 000570): Train loss 0.211, Val loss 0.806\n",
      "Ep 5 (Step 000575): Train loss 0.215, Val loss 0.810\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the chemical formula for sodium carbonate?\n",
      "Training completed in 3.65 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iKQ9jddpVYLw"
   },
   "outputs": [],
   "source": [
    "# Save the model in case we want to reuse the model later\n",
    "torch.save(model.state_dict(), \"instruct_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "GarStmfHSfQ5",
    "outputId": "cfe76f59-27f6-4d16-da02-d26b15c781a4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from previous_chapters import plot_losses\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7qnzLQ8lWfbU"
   },
   "source": [
    "### Using the LLM to follow instructions\n",
    "\n",
    "Let's use the finetuned GPT model in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eYLEUOHvWhxY",
    "outputId": "20d7e452-e933-4717-fe8a-891ded9f7fe2"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "PytorchStreamReader failed reading zip archive: failed finding central directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_612877/263216846.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# when using server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_state_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/haszun/june-20/instruct_model.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# when using colab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#model_state_dict = torch.load(\"instruct_model.pth\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;31m# reset back to the original position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0morig_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m_is_torchscript_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                     warnings.warn(\"'torch.load' received a zip file that looks like a TorchScript archive\"\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed reading zip archive: failed finding central directory"
     ]
    }
   ],
   "source": [
    "# Load the newly trained model\n",
    "\n",
    "# when using server\n",
    "model_state_dict = torch.load(\"/home/haszun/june-20/instruct_model.pth\")\n",
    "# when using colab\n",
    "#model_state_dict = torch.load(\"instruct_model.pth\")\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-b90h_LSzKi"
   },
   "source": [
    "### Run instruction model on test dataset and extract responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EOX5DJCTSfTZ"
   },
   "outputs": [],
   "source": [
    "def extract_response(response):\n",
    "    return response[response.find(\"\\n### Response\")+len(\"\\n### Response:\")+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Oe32RlgSfWF",
    "outputId": "eb4ede7b-426f-4376-cce4-9ed11935b72f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Classify each sentence as either declarative, interrogative, imperative, or exclamatory.\n",
      "\n",
      "### Input:\n",
      "Please open the door.\n",
      "\n",
      "Correct response:\n",
      ">> The classification of the sentence 'Please open the door.' is imperative.\n",
      "\n",
      "Model response:\n",
      ">> Clarity is a function of time.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence to use a negative adverb.\n",
      "\n",
      "### Input:\n",
      "She always remembers to call.\n",
      "\n",
      "Correct response:\n",
      ">> She never forgets to call.\n",
      "\n",
      "Model response:\n",
      ">> She always calls.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert 50 miles per hour to kilometers per hour.\n",
      "\n",
      "Correct response:\n",
      ">> 50 miles per hour is approximately 80.47 kilometers per hour.\n",
      "\n",
      "Model response:\n",
      ">> 50 miles per hour is approximately 32.07 kilometers per hour.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# last three samples from test dataset\n",
    "for entry in test_data[-3:]:\n",
    "\n",
    "    # prepare input\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    # run inference\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "\n",
    "    # post process output\n",
    "    response = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = extract_response(response)\n",
    "\n",
    "    # print output\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWNh-bTGjJ4X"
   },
   "source": [
    "### Run instruction model on custom inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C5zwksbsZrgN"
   },
   "outputs": [],
   "source": [
    "def run_instruction_model(instruction_text, input_text):\n",
    "\n",
    "  # prepare inputs\n",
    "  input_text = format_input({'instruction': instruction_text, 'input': input_text})\n",
    "\n",
    "  # model inference\n",
    "  token_ids = generate(\n",
    "      model=model,\n",
    "      idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "      max_new_tokens=256,\n",
    "      context_size=BASE_CONFIG[\"context_length\"],\n",
    "      eos_id=50256\n",
    "  )\n",
    "\n",
    "  # post process output\n",
    "  response = token_ids_to_text(token_ids, tokenizer)\n",
    "  response_text = extract_response(response)\n",
    "\n",
    "  # print output and return the output\n",
    "  print(input_text)\n",
    "  print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "  print(\"-------------------------------------\")\n",
    "  return response_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z5CxBSxRbq-0",
    "outputId": "04e7fb04-8b8e-4bc8-ea2c-5373e4aa2b0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "instruction = \"Rewrite the sentence using a simile.\"\n",
    "input = \"The car is very fast.\"\n",
    "\n",
    "output_text = run_instruction_model(instruction, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xTWUzFUGPeUn",
    "outputId": "35bad282-7cd6-427f-bd1d-28fc5c816549"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Is the following text a spam?\n",
      "\n",
      "### Input:\n",
      "You are a winner you have been specially selected to receive $1000 cash or a $2000 award.\n",
      "\n",
      "Model response:\n",
      ">> The text was a spam.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "instruction_2 = \"Is the following text a spam?\"\n",
    "input_2 = \"You are a winner you have been specially selected to receive $1000 cash or a $2000 award.\"\n",
    "\n",
    "output_text2 = run_instruction_model(instruction_2, input_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZKwhY-LKcsSd",
    "outputId": "2e25e0f9-04a3-4f5a-8675-11b72576ccb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Translate into French.\n",
      "\n",
      "### Input:\n",
      "Hello, How are you?\n",
      "\n",
      "Model response:\n",
      ">> I am in France.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "instruction_3 = \"Translate into French.\"\n",
    "input_3 = \"Hello, How are you?\"\n",
    "\n",
    "output_text3 = run_instruction_model(instruction_3, input_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jb_XxvhFdnbP",
    "outputId": "c6e5e37f-1e3a-4d4a-df3b-a739d05b4dbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert 3 meters to centimeters.\n",
      "\n",
      "Model response:\n",
      ">> 3 meters is 300 centimeters.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "instruction_4 = \"Convert 3 meters to centimeters.\"\n",
    "input_4 = \"\"\n",
    "\n",
    "output_text3 = run_instruction_model(instruction_4, input_4)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "UiSHr_2ZK_HN",
    "TLwvJSA_JmHv",
    "9zlHTIWOMawG",
    "a9XP46g1Z9Jp",
    "M4qgSqsmB8oU"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
